{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Embeddings & Clustering\n",
    "\n",
    "**Duration:** ~15 minutes \n",
    "**Module:** 5 - GDS with Python \n",
    "**Dataset:** Cora Citation Network (continued)\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- How to create node embeddings with FastRP\n",
    "- How to cluster papers using K-Means on embeddings\n",
    "- Production patterns for GDS workflows\n",
    "- How to clean up graph projections\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completion of Lessons 1-3 (all centrality, communities, and features computed)\n",
    "- Graph `cora-graph-ml` should exist in memory (created in Lesson 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Setup Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from graphdatascience import GraphDataScience\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load credentials from .env\n",
    "load_dotenv()\n",
    "uri = os.getenv('NEO4J_URI')\n",
    "username = os.getenv('NEO4J_USERNAME')\n",
    "password = os.getenv('NEO4J_PASSWORD')\n",
    "\n",
    "# Connect to GDS\n",
    "aura_ds = 'neo4j+s://' in uri if uri else False\n",
    "gds = GraphDataScience(uri, auth=(username, password), aura_ds=aura_ds)\n",
    "\n",
    "# Get the graph object from Lesson 3 (with scaled features)\n",
    "G = gds.graph.get(\"cora-graph-ml\")\n",
    "\n",
    "print(f\"Connected to GDS version: {gds.version()}\")\n",
    "print(f\"Graph '{G.name()}' ready: {G.node_count():,} nodes\")\n",
    "print(f\"Node properties: {G.node_properties('Paper')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: What are Node Embeddings?\n",
    "\n",
    "**The concept:**\n",
    "- Transform nodes into dense vector representations (embeddings)\n",
    "- Similar nodes -> similar vectors\n",
    "- Enables machine learning on graphs (clustering, classification, link prediction)\n",
    "\n",
    "**FastRP (Fast Random Projection):**\n",
    "- Creates embeddings from graph structure + node properties\n",
    "- Much faster than deep learning approaches (e.g., GraphSAGE)\n",
    "- Works well on large graphs (millions of nodes)\n",
    "- Captures both local and global graph structure\n",
    "\n",
    "**What influences the embedding?**\n",
    "1. **Graph structure:** Papers citing similar papers get similar embeddings\n",
    "2. **Node features:** Papers with similar content get similar embeddings\n",
    "3. **Centrality:** We included PageRank & Betweenness in our features!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Value of Embeddings\n",
    "\n",
    "**In e-commerce:**\n",
    "- Product recommendations based on user behavior graph\n",
    "\n",
    "**In fraud detection:**\n",
    "- Classify suspicious accounts based on transaction patterns\n",
    "\n",
    "**In citation networks:**\n",
    "- Recommend papers for researchers to read\n",
    "- Predict future citations (link prediction)\n",
    "- Cluster papers into research topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Creating Embeddings with FastRP\n",
    "\n",
    "Run FastRP using the scaled features from Lesson 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FastRP to create 128-dimensional embeddings\n",
    "# Use MUTATE mode to keep embeddings in memory (not written to database yet)\n",
    "\n",
    "fastrp_result = gds.fastRP.mutate(\n",
    "    G,\n",
    "    mutateProperty='embedding',\n",
    "    embeddingDimension=128,\n",
    "    featureProperties=['scaledFeatures'],  # Use our prepared features from Lesson 3\n",
    "    randomSeed=42,  # For reproducibility\n",
    "    iterationWeights=[0.0, 1.0, 1.0]  # Weight more recent iterations\n",
    ")\n",
    "\n",
    "print(f\"Created {fastrp_result['nodePropertiesWritten']:,} embeddings\")\n",
    "print(f\"  Embedding dimension: 128\")\n",
    "print(f\"  Using property: scaledFeatures (1,435 dimensions)\")\n",
    "print(f\"  Compressed to: 128 dimensions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What just happened?**\n",
    "- FastRP created a 128-dimensional vector for each paper\n",
    "- Used **MUTATE** mode (keeps embeddings in the projection, doesn't write to DB)\n",
    "- Combined graph structure with content features\n",
    "- `iterationWeights` controls how much to weight different \"hops\" in the graph\n",
    "\n",
    "**Why MUTATE instead of WRITE?**\n",
    "- Faster (no database write)\n",
    "- Useful for intermediate results\n",
    "- Can still stream/write later if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Clustering Papers with K-Means\n",
    "\n",
    "Use the embeddings to cluster papers into research topics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run K-Means clustering on the embeddings\n",
    "# We know there are 7 official subjects, so let's try k=7\n",
    "\n",
    "kmeans_result = gds.kmeans.write(\n",
    "    G,\n",
    "    nodeProperty='embedding',\n",
    "    k=7,  # 7 clusters (same as number of subjects)\n",
    "    writeProperty='kmeans7_cluster',\n",
    "    randomSeed=42,\n",
    "    maxIterations=100\n",
    ")\n",
    "\n",
    "print(f\"Clustered {kmeans_result['nodePropertiesWritten']:,} papers into 7 clusters\")\n",
    "print(f\"  Computation time: {kmeans_result['computeMillis']:,}ms\")\n",
    "print(f\"  Cluster distribution: min={kmeans_result['communityDistribution']['min']}, max={kmeans_result['communityDistribution']['max']}, mean={kmeans_result['communityDistribution']['mean']:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What just happened?**\n",
    "- K-Means clustered papers based on their embeddings\n",
    "- Used `k=7` because we have 7 subject categories\n",
    "- Algorithm converged after finding optimal cluster assignments\n",
    "- Each paper is now assigned to a cluster (0-6)\n",
    "\n",
    "**Key insight:**\n",
    "K-Means clusters papers based on:\n",
    "- **Graph structure** (citation patterns)\n",
    "- **Content similarity** (word features)\n",
    "- **Centrality** (PageRank + Betweenness)\n",
    "\n",
    "Compare with **Louvain** from Lesson 3:\n",
    "- **Louvain:** Pure graph structure (modularity optimization)\n",
    "- **K-Means on embeddings:** Structure + content + centrality combined!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Analyzing Clusters\n",
    "\n",
    "Let's analyze how the K-Means clusters relate to the actual paper subjects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare K-Means clusters with official subjects\n",
    "q_cluster_analysis = \"\"\"\n",
    "MATCH (p:Paper)\n",
    "WHERE p.kmeans7_cluster IS NOT NULL\n",
    "RETURN \n",
    "    p.kmeans7_cluster AS cluster,\n",
    "    p.subject AS subject,\n",
    "    count(*) AS count\n",
    "ORDER BY cluster, count DESC\n",
    "\"\"\"\n",
    "\n",
    "df_clusters = gds.run_cypher(q_cluster_analysis)\n",
    "print(\"K-Means Cluster Composition by Subject:\")\n",
    "print(\"=\"*60)\n",
    "display(df_clusters.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "Look at how papers are distributed across clusters:\n",
    "- **Pure clusters:** Dominated by one subject \u2192 tightly focused research area\n",
    "- **Mixed clusters:** Multiple subjects \u2192 interdisciplinary research\n",
    "- **Comparison:** Some clusters align well with subjects, others reveal new groupings\n",
    "\n",
    "**This is powerful because:**\n",
    "- Clusters are based on BOTH structure AND content AND centrality\n",
    "- May reveal research groupings not captured by formal subject labels\n",
    "- Can identify emerging research areas that cross traditional boundaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Production Patterns\n",
    "\n",
    "Best practices for using GDS in real applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pattern 1: Estimate Memory Before Running\n",
    "\n",
    "Always estimate memory for large graphs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate memory for PageRank on a large graph\n",
    "estimate = gds.pageRank.write.estimate(\n",
    "    G,\n",
    "    writeProperty='pageRank_test'\n",
    ")\n",
    "\n",
    "print(\"PageRank Memory Estimate:\")\n",
    "print(f\"  Min bytes: {estimate['requiredMemory'][0]}\")\n",
    "print(f\"  Max bytes: {estimate['treeView'][0]}\")\n",
    "print(f\"  Node count: {estimate['nodeCount'][0]:,}\")\n",
    "print(f\"  Relationship count: {estimate['relationshipCount'][0]:,}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 2: Use STREAM for Exploration, WRITE for Production\n",
    "\n",
    "**STREAM mode:**\n",
    "- Returns results as pandas DataFrame\n",
    "- No database writes\n",
    "- Good for exploration and testing\n",
    "\n",
    "**MUTATE mode:**\n",
    "- Stores results in projection (not database)\n",
    "- Good for intermediate steps in pipeline\n",
    "\n",
    "**WRITE mode:**\n",
    "- Stores results as node/relationship properties\n",
    "- Persists for future queries\n",
    "- Good for production\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 3: List and Clean Up Projections\n",
    "\n",
    "Always clean up projections when done!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all graph projections\n",
    "projections = gds.graph.list()\n",
    "print(\"Current graph projections:\")\n",
    "display(projections[['graphName', 'nodeCount', 'relationshipCount', 'memoryUsage']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To drop a projection when you're done:\n",
    "# (Uncomment to run)\n",
    "\n",
    "# gds.graph.drop(G)\n",
    "# print(\"Dropped projection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 4: Batch Processing Pipeline\n",
    "\n",
    "Example production workflow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def citation_analysis_pipeline(gds_client, graph_name=\"citation-pipeline\"):\n",
    " \"\"\"\n",
    " Complete citation network analysis pipeline.\n",
    " \"\"\"\n",
    " print(\"Step 1: Project graph\")\n",
    " G, _ = gds_client.graph.project(\n",
    " graph_name,\n",
    " {\"Paper\": {\"properties\": [\"features\", \"subjectClass\"]}},\n",
    " {\"CITES\": {\"orientation\": \"UNDIRECTED\"}}\n",
    " )\n",
    " \n",
    " print(\"Step 2: Compute centrality metrics\")\n",
    " gds_client.pageRank.mutate(G, mutateProperty='pr')\n",
    " gds_client.betweenness.mutate(G, mutateProperty='bc')\n",
    " \n",
    " print(\"Step 3: Detect communities\")\n",
    " gds_client.louvain.mutate(G, mutateProperty='community')\n",
    " \n",
    " print(\"Step 4: Create embeddings\")\n",
    " gds_client.fastRP.mutate(\n",
    " G,\n",
    " mutateProperty='emb',\n",
    " embeddingDimension=128,\n",
    " featureProperties=['features']\n",
    " )\n",
    " \n",
    " print(\"Step 5: Compute similarity\")\n",
    " similarity = gds_client.nodeSimilarity.stream(\n",
    " G,\n",
    " nodeProperties=['emb'],\n",
    " topK=10\n",
    " )\n",
    " \n",
    " print(\"Step 6: Clean up\")\n",
    " gds_client.graph.drop(G)\n",
    " \n",
    " return pd.DataFrame(similarity)\n",
    "\n",
    "# This pattern is perfect for scheduled batch jobs!\n",
    "print(\"\\nProduction Pipeline Template Created \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: What You Accomplished\n",
    "\n",
    "You've completed the entire Python GDS workflow!\n",
    "\n",
    "- Created node embeddings with FastRP (combining structure + content)\n",
    "- Clustered papers with K-Means\n",
    "- Learned production patterns (estimate, stream/mutate/write, cleanup)\n",
    "- Built a complete analysis pipeline\n",
    "\n",
    "**Module 5 Complete!**\n",
    "\n",
    "### What You've Learned Across All Lessons\n",
    "\n",
    "**Lesson 1:** Setup, data loading, projections, PageRank \n",
    "**Lesson 2:** Betweenness Centrality, bridge analysis \n",
    "**Lesson 3:** Louvain communities, feature engineering \n",
    "**Lesson 4:** FastRP embeddings, similarity, K-Means, production patterns\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Python GDS client** simplifies graph data science workflows\n",
    "2. **Combine multiple algorithms** for richer insights\n",
    "3. **Structure + Content + Centrality** -> powerful embeddings\n",
    "4. **Production patterns** ensure scalable, maintainable code\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Apply these techniques to your own datasets\n",
    "- Explore other GDS algorithms (see GDS documentation)\n",
    "- Build recommendation systems, fraud detection, knowledge graphs\n",
    "- Consider **Aura Graph Analytics** for on-demand scalable GDS\n",
    ""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}